##################################################################################################

Linux
	开机自启的方式:
		1.编辑/etc/rc.local文件,直接写上需要运行的命令即可
		2.编写脚本,放在/etc/profile.d/目录下,程序启动后会自动执行该目录下的shell脚本
		3.通过chkconfig命令设置
##################################################################################################

*TCP/IP协议
	TCP/IP5层模型
	应用层
	传输层
		TCP:
			建立连接：
				三次握手
			传输数据（双工）：
				四次握手
			断开连接：
				四次断开
		UDP:
	网络层
		IP协议:
		路由器:
	数据链路层
		ARP：
			概要：
				通过目标IP地址查找相对于接收数据包的网络设备MAC地址，如果目标IP与发送端IP不在同一网段，可以通过ARP查找下一跳路由器的MAC地址。
			工作方式：
				ARP是借助ARP请求与ARP响应两种类型的包来确定MAC地址的。在首次进行数据传输时，发送端并不知道接收端设备的MAC地址。因此发送端会在同一链路上进行广播
				ARP请求包，同一链路上的设备会解析ARP请求包，查看其中的目标IP是否是自己。如果不是则丢弃，如果是那么这个节点则返回一个ARP响应包，里面包含该节点的
				MAC地址。同时双方在发送请求包和回应响应包时，交换机会记录他们的MAC地址与IP地址的对照关系，并将这种对照关系存入MAC地址表中，这样下一次传输时就无
				须广播，而是直接查看MAC地址表直接获取IP地址。
				发送流程：
				查看MAC地址表
					有IP地址对照的MAC地址；直接发送
					没有对照关系；
						先将发送端的IP地址与MAC地址对照关系写入MAC表中。
						发送端进行广播，发送ARP请求包，包中有目标地址的IP地址信息。
						接收到广播的各节点解析ARP请求包，查看目标IP是否是自己，不是；则将包丢弃。
						是；则回应一个ARP回应包，包中有目标地址的MAC地址。
						再将接收端的IP地址与MAC地址对照关系写入MAC表中。
						根据MAC地址表，将响应包发给发送端。
						发送端发送数据包。
		RARP：
			概要：
				通过MAC地址查找相对于的IP地址。
	
	物理层
##################################################################################################

*Shell
##################################################################################################

*HTTP（工作模式，优化，事故）
##################################################################################################

*Nginx（优化，安全）
	0、nginx原理
		nginx如何工作：
			通过查找配置文件将客户端请求映射到一个location block（location是Nginx配置中的一个指令，用于匹配URL），而在这个location中所匹配的每个指令将会启动不同的模块去完成相应工作。
		nginx的模块：
			核心模块、基础模块、第三方模块
			从功能上分为以下三种：
				Handlers（处理器模块）：此类模块直接处理请求，并进行输出内容和修改headers信息等操作，一般Handlers处理器模块只能有一个
				Fiters（过滤器模块）：对处理器模块输出的内容进行修改，最后由nginx输出
				Proxies（代理类模块）：此类模块主要与一些后端服务进行交互，如：FastCGI等，实现服务器代理和负载均衡等功能
		nginx如何处理请求:
			接收到HTTP请求时，
		何为代理服务器:
		什么是FastCGI:
		nginx如何实现高并发:
			异步,非阻塞
			nginx采用一个master进程,多个worker进程的模式.
				master进程负责收集,分发请求.当有一个请求过来时,master会拉起一个worker进程负责处理这个请求
				worker进程处理这个请求时,worker不是全程处理,而是将其处理到有可能发生阻塞的地方时,注册一个事件,这个事件会记录阻塞的状态,然后worker会进入休息状态,这是worker可以处理新的请求,如果阻塞状态改变,worker会继续处理之前的请求.
			非阻塞:不会等待阻塞,在发生阻塞时,worker注册一个事件,记录阻塞状态,然后等待新的请求
			
			”同步“就好比：你去外地上学(人生地不熟)，突然生活费不够了；此时你决定打电话回家，通知家里转生活费过来，可是当你拨出电话时，对方一直处于待接听状态(即：打不通，联系不上)(阻塞发生)，为了拿到生活费，你就不停的oncall、等待，最终可能不能及时要到生活费，导致你今天要做的事都没有完成，而白白花掉了时间。
			“异步”就是：在你打完电话发现没人接听时(阻塞发生)，猜想：对方可能在忙，暂时无法接听电话，所以你发了一条短信(或者语音留言，亦或是其他的方式)通知对方(注册事件记录)后便忙其他要紧的事了；这时你就不需要持续不断的拨打电话，还可以做其他事情；待一定时间后，对方看到你的留言便回复响应你，当然对方可能转钱也可能不转钱。但是整个一天下来，你还做了很多事情。 或者说你找室友临时借了一笔钱，又开始happy的上学时光了。
			
			同步会一直等待(被阻塞),直到有结果返回
			异步会直接先注册一个事件然后返回,但是没有结果,等到

		为什么nginx不使用多线程:
			进程与线程的区别,为什么线程比进程小:
				进程:每个进程都有独立的代码和数据空间
				线程:同一类线程共享代码和数据空间
			每个线程或进程都会被分配cpu和内存(线程所占用cpu和内存比进程小的多,所以worker(Apache的一种工作模式)支持比prefork(Apache的一种工作模式)高的并发),并发过大会耗尽服务器资源
			nginx采用单线程来异步非阻塞处理请求,不会为每个请求分配cpu和内存资源,节省了大量资源,同时也减少了大量的cpu的上下文切换
				cpu的上下文切换:是指cpu从一个进程或线程切换到另一个进程或线程

	
	0、调优		
		自定义错误页面:
			error_page 404 /40x.html;
		安装状态查询模块
			页面解析:
				#活跃连接数
				Active connections:1   
				#已经接受客户端的连接总数    已经回应客户端请求的总数     客户端发送的请求连接总数 
				server                  accepts                 handled requests
				4                              4                              6
				#当前服务器正在读取客户端请求头的数量   当前服务器正在写响应信息的数量   当前有多少客户端等待服务端响应
				Reading:0                        Writing:1                   Waiting:0
			配置状态页面限制本地访问:
				vim /usr/local/nginx/conf/nginx.conf
					location /status {
						allow 允许的IP1;
						allow 允许的IP2;
						deny all;#拒绝剩余所有
					}

		并发量优化:
			worker_processes:worker进程数量
			worker_connections:每个worker最大同时提供服务的客户端数量
			两者结合可以获得每秒可以服务的最大客户端数:最大客户端数/秒=工作进程*worker数
			为什么要优化:
				提高单台web服务器处理的访问量,提高资源利用率,节约成本
			优化思路:
				先优化worker进程数量,设置为auto,自动根据cpu核心数开启相应workS
				然后优化每个worker最大并发量,每个work最大并发量为65535,work最大并发量不能超过最大文件打开数,所以还需要优化linux系统的最大文件打开数量限制
			具体配置:
			vim /usr/local/nginx/conf/nginx.conf
			worker_processes auto;
			worker_connections 65535;
			
			内核参数优化:
			ulimit -a     #查看所有属性值
			ulimit -Hn 100000   #临时设置硬限制
			ulimit -Sn 100000   #临时设置软限制
			vim /etc/security/limits.conf    #永久设置
			#    用户或组  硬限制或软限制		需要限制的项目		限制的值
				* 	soft 			nofile 		100000
                         * 	hard 			nofile 		100000
		
		优化nginx数据包头优化:
			为什么要优化:
				在nginx配置文件中,设置client_header_buffer_size和large_client_header_buffer_size的值,来规定nginx默认的header长度上限.
				其中client_header_buffer_size是规定nginx默认的header上限
				large_client_header_buffer_size则是当header超过默认长度之后的最大允许长度.
					第一个参数为:最多允许几个超出默认长度的请求一起访问
					第二个参数为:为每个请求开辟相应的缓存空间
				
				在实际环境中,如果请求的header都很大,那么应该直接设置client_header_buffer_size的值,这样能减少一次内存分配;如果只有少量请求的header很大,那么应该使用large_client_header_buffer_size,这样就只会在处理大header是才会分配更多内存空间,从而减少内存空间的浪费

			如何优化:
				vim /usr/local/nginx/conf/nginx.conf
				http{
					#默认请求包头信息的缓存
					client_header_buffer_size 1k;
					#大请求包头信息的缓存个数与容量
					large_client_header_buffer_size 4 4k;
				}
		
		浏览器本地缓存静态数据:
			为什么要优化:
				提高网站的访问速度(有了缓存,浏览器可以直接从本地调用资源,不需要请求服务器资源)
				减轻服务器的负担(无需请求服务器资源,减轻了负担)
			如何优化:
				网站首页缓存1分钟,因为首页包含的链接和文件列表经常更新
				文字类文章缓存一天,因为这类文章一旦写完就不会修改,同时缓存也占用空间,所以无需缓存太久
				所有的图片类的都应该缓存30天以上,因为从磁盘检索图片是非常消耗资源的

				配置文件:
				vim /usr/local/nginx/conf/nginx.conf
				location / {
					expires 1m;				
				}
				location /articles {
					expires 1d;
				}
				location ~*\.(img|jpg|gif)$ {
					expires 30d;	
				}
			浏览器中查看缓存时间:
				以firefox为例:
				地址栏中输入:about:cache

		启用Gzip压缩:
			为什么要优化:压缩文件进行传输,不仅可以提高用户的使用感受(访问变快了),还可以节省大量的出口带宽(需要传输的文件变小了),一举两得,但是会消耗一定的cpu资源(对文件进行压缩需要占用一部分cpu资源).
			在进行文件压缩时,图片/视频等多媒体资源不应该使用压缩,而是设置缓存,使这类资源缓存在用户本地,因为这类资源的压缩效果不好,而且通常很大(占用带宽).
			真正应该设置传输时压缩的文件应该是css,js,xml,html这类文本文件,这类文件的压缩比非常高(压缩之后文件很小),压缩效果好,而且这类文件变更的比较频繁(比如首页等内容经常变),使用压缩后会提高用户访问速度.
			
			如何优化:
				vim /usr/local/nginx/conf/nginx.conf
				http {
					...
					gzip on;    #开启gzip压缩
					gzip_buffers 4 16k;    #设置压缩缓冲区大小
						#缓冲区:
							gizp_buffers缓冲区:缓存压缩过得文件,如请求的文件缓冲区有,就直接从缓冲区返回,不再需要压缩,设置gzip缓冲区大小就是设置存储缓存文件空间
							现将处理的数据放到缓冲区,客户端从缓冲区一次性读取数据,减少客户端与nginx的连接次数.
							场景:
							客户端到nginx代理服务器到后端服务器
							果客户端接收数据慢,没有缓冲区,nginx需要一直跟后端服务器保持连接,以保证客户端请求的数据能正常传输,设置缓冲区之后,nginx代理服务器暂时缓存客户端请求数据,客户端读取nginx缓冲区,nginx代理就可以与后端服务器断开连接
						
					gzip_min_length 1000;  #小于1000字节的文件不进行压缩
					gzip_comp_level 4;  #压缩比例;1最小,处理速度最快,传输最慢,9最大,处理速度最慢,传输最慢
					gzip_types text/plain text/css application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript;  #设置需要压缩的文件类型
					gzip_disable "MSIE [1-6]\."
				}
			实现效果:
				先生成一个100K左右的文本文件,将文件放到nginx html目录下
				firefox访问测试,打开控制台查看开启gzip和未开启的传输数据大小区别

		日志切割:
			为什么要切割:
				实际工作中,日志文件如果不进行处理,单个日志文件的大小会越变越大,如果想要删除之前无用的旧日志(6个月甚至1年前的日志),不对日志进行切割将会非常难处理(单个文件太大,打开读取时间太长),所以定期对日志进行切割是个好习惯
			何如实现:
				将旧日志文件按切割时间重命名,再用kill发送USR1信号给nginx进程,告知nginx平滑重启,重新打开日志文件(因为有句柄的存在,即使移动了日志文件,nginx依然会将日志存入旧文件,重新打开日志文件就是重新生成新的日志文件)
				切割脚本:
				#!/bin/bash
				#储存当前系统时间
				date=`date +%Y-%m-%d`
				#储存nginx日志目录
				logpath=/usr/local/nginx/logs
				mv $logpath/access.log $logpath/access-$date.log
				mv $logpath/error.log $logpath/error-$date.log
				kill -USR1 $(cat /usr/local/nginx/logs/nginx.pid)
				最后将脚本写入周期性计划任务(每周五4点执行日志切割):
				crontab -e
				00 04 * * 5 /usr/local/nginx/logs/logbak.sh			

		服务器内存缓存:
			为什么要优化:
				如果需要处理大量静态文件，可以将文件缓存在内存，下次访问会更快
			如何优化:
				http { 
				open_file_cache          max=2000  inactive=20s;
        				open_file_cache_valid    60s;
        				open_file_cache_min_uses 5;
        				open_file_cache_errors   off;
					//设置服务器最大缓存2000个文件句柄，关闭20秒内无请求的文件句柄
					//文件句柄的有效时间是60秒，60秒后过期
					//只有访问次数超过5次会被缓存
				} 			

	1、nginx的安装
		源码安装：
			依赖：
				pcre-devel、openssl-devel、gcc
			configure安装配置文件：
				可以指定安装路径、启动服务指定用户、添加/删除安装模块
	2、nginx程序升级
		源码安装，配置configure文件
		只需要执行到make这一步即可
		这样会在安装包目录生成一个nginx包
		将包内的bbjs/nginx文件替换掉原来nginx目录下的sbin/nginx即可
		在替换之前要给就/sbin/nginx做备份，避免覆盖之后服务无法启动
		
		程序升级的意义：
			1、原先的程序版本出现重大漏洞，需要紧急修复
			2、现在的程序出现问题，需要修复
			3、新功能

	3、自定义安装模块
		安装前查看所有模块：
			./configure --help
				--without字样的模块会默认安装，without可以在安装时将他们禁用，
				在后面的安全优化，和性能优化中，需要将一部分默认安装的模块禁用
		安装完成后可以/usr/local/nginx/sbin/nginx -V查看安装的模块和各配置信息（根据configure文件的配置信息）
		
	4、动态加载模块
		已经安装好的nginx，根据业务需求动态的添加模块
			将nginx升级的步骤做一遍即可，需要注意备份和跟之前的配置信息保持一致
	
	5、nginx用户认证
		修改nginx配置文件，添加如下配置：
			vim /usr/local/nginx/conf/nginx.conf
				http {
				...
					server {
						listen 80;
						...
						#提示用户的信息
						auth_basic "Input password";
						#用户名和密码验证文件，需要自己创建
						auth_basic_user_file "/usr/local/nginx/pass";
					}
				}
	
	6、nginx虚拟主机
		虚拟主机，一个服务器，一个nginx，实现多个网站
		
		基于域名的虚拟主机：
				修改nginx配置文件，添加如下配置：
					#添加一个server{}块，设置server_name为新域名，这样可以根据用户访问的域名进行匹配
					server {
						listen 80;
						server_name www.test2.com;
						
						location / {
							root html;
							#先查找file1文件是否存在，如果存在则返回file1页面，如果不存在就匹配下一个
							try_files file1.html file2.html index.html;
						}
					}
		基于ip地址的虚拟主机：
		基于端口的虚拟主机：
	
	7、加密网站
		需要模块:
			--with-http_ssl_module模块
		生成私钥与证书
			cd /usr/local/nginx/conf
			生成私钥：openssl genrsa > cert.key
			生成证书：openssl req -new -x509 -key cert.key > cert.pem
		修改配置文件：
			#nginx配置文件中自带加密虚拟主机的配置，只需要删除注释，修改证书和私钥路径即可
			vim +100 /usr/local/nginx/conf/nginx.conf
				ssl_certificate cert.pem;
				ssl_certificate_key cert.key;
		访问测试：
			https://127.0.0.1
			
	8、nginx反向代理：
		目的：
			让处于不同网段的服务器和客户端进行交流。客户端访问nginx调度服务器，调度服务器通过调度算法，将请求
			转发给集群服务器处理；在集群服务器看来，是调度服务器发起的请求，所以讲相应资源返回给调度服务器，
			调度服务器再将资源返回给客户端；在客户端看来，调度服务器就是web服务器。
			
		实验拓扑：
		
						   -------WEB服务器1
		client----nginx代理
						   -------WEB服务器2
			
		配置反向代理：
			#创建集群池，添加服务器，指定服务端口，设置监听端口
			vim /usr/local/nginx/conf
				http {
					upstream 集群池名 {
						#指定调度算法，根据源地址hash计算，使相同ip始终访问同一台服务器，实现session共享
						ip_hash;
						#集群服务器，weight设置权重，max_fails设置连接时允许最大失败次数，fail_timeout超过
						最大连接次数后，等待30秒再次尝试连接
						server 服务器1IP:80 weight=1 max_fails=1 fail_timeout=30;
						server 服务器2IP:80 weight=1 max_fails=1 fail_timeout=30;
					}
					server {
					...
					#将客户端的http服务请求转发给集群处理
					proxy_pass http://集群池名;
					}
				}
			重新加载nginx配置：
				/usr/local/nginx/sbin/nginx -s reload
			客户端测试：
				curl http://调度服务器地址
				
			
			
	9、nginx实现四层TCP/UDP调度
		正常的nginx调度只能实现第7层的http协议调度，而TCP/UDP是四层的传输协议，所以实现TCP/UDP的调度，
		需要安装额外模块；四层可以使得nginx支持更多的运用，比如对ssh的调度。
		但是四层调度功能只有nginx1.9之后的版本才支持。
		
		实验拓扑：
		
						   -------SSH服务器1
		client----nginx代理
						   -------SSH服务器2
						   
		需要模块：
			--with-stream
		修改配置文件：
			#创建集群池，添加服务器，指定服务端口，设置监听端口
			vim /usr/local/nginx/conf
			#定义集群池
			stream {
				upstream 集群池名 {
					server ssh服务器1地址:22;
					server ssh服务器2地址:22;
				}
				
				server {
					listen 监听端口;
					proxy_connect_timeout 1s;
					proxy_timeout 3s;
					#将请求交给集群处理
					proxy_pass 集群池名;
				}
			}
			http {
			...
			}
		nginx重新加载配置文件
			/usr/local/nginx/sbin/nginx -s reload
		客户端访问测试
			ssh 调度服务器地址 -p 监听端口
			
	10、nginx负载均衡
		两个模块实现nginx负载均衡：
			stream、proxy
		stream：
			定义集群池以及集群服务器
			可以设置调度算法，实现负载均衡
		proxy：
			反向代理
			将客户端的请求转发给服务器
		
	11、nginx常见错误代码及处理方案
		302：
		403：
		499：
		502：
		504：
##################################################################################################
			
*Tomcat
	
##################################################################################################

*Lvs:
	原理及组成:
		原理:
			客户端向DS发送访问服务请求
			DS将请求发送至内核空间
			PREROUNTING链首先接受到请求
			确认请求的目标地址(VIP)是本机, 将请求发送给INPUT链
			ipvs工作在INPUT链上,ipvs确认请求的服务与集群服务一致,强行修改请求包的目标地址和端口,发送给POSTROUTING链
			POSTROUTING链根据目标地址(RIP)发送给服务器群组
		组成:
			由数据包处理,调度算法,系统管理与配置三个模块和虚拟服务器和真实服务器链表组成
	三种工作模式:
		NAT模式:
			特性:
				RS必须将网关设置为DS地址
				所有的请求和回应都要经过DS,DS很容易成为瓶颈
				RS和DS必须在同一网段
			配置方法:
				RS安装web服务器,并确保页面访问正常
				RS设置网关为DS地址
				DS确保内核开启路由转发功能,ip_forward=1
				DS安装ipvsadm管理工具
				添加调度规则,规则中调度服务器地址为VIP
				将配置保存为永久,ipvsadm-save -n > /etc/sysconfig/ipvsadm
		DR模式:
			特性:
				RS不允许网关指向DS
			`	RS必须与DS在同一网络
				RS和DS都要设置VIP
				RS的VIP设置在回环网卡上
				所有的请求必须经过DS调度服务器
				所有的回应必须不经过DS调度服务器
			配置方法:
				RS安装web服务器,并确保页面访问正常
				RS配置VIP在lo网卡上,复制lo网卡配置,命名为lo:0,修改IP为VIP,子网掩码32位
				RS重启网络服务,查看网卡信息,systemctl restart network;ifconfig
				RS上还需要修改网卡内核参数,arp_ignore=1,arp_announce=2
					可以添加如下配置到/etc/sysctl.conf
							net.ipv4.conf.lo.arp_ignore = 1
							net.ipv4.conf.all.arp_ignore = 1
							net.ipv4.conf.lo.arp_announce = 2
							net.ipv4.conf.all.arp_announce = 2
						然后sysctl -p重新加载配置
					或者直接echo:
							echo 1 > /proc/sys/net/ipv4/conf/lo/arp_ignore
							echo 1 > /proc/sys/net/ipv4/conf/all/arp_ignore
							echo 2 > /proc/sys/net/ipv4/conf/lo/arp_announce
							echo 2 > /proc/sys/net/ipv4/conf/all/arp_announce
		Tunnel模式:		
	调度算法:
		rr:轮训,依次循环调度到每台服务器上,缺点:如果服务器上的连接数不一样,就无法达到真正的负载均衡效果
		wrr:带权重的轮训,如果某台服务器性能更好,可以设置权重使其接受更多请求,缺点:跟rr一样		
		lc:最小连接,根据RS的连接数将请求发给连接数最少的服务器,缺点:无法使用session
		sh:源地址哈希,根据源地址进行哈希算法,固定访问到同一台服务器,缺点:学校,公司这种大量请求的地方都是使用同一个IP,依然会导致调度不均匀
		dh:目标地址哈希,为了实现资源的分类管理
##################################################################################################

*Keepalived
	防止单点故障:VRRP
	工作原理:
		检测每个服务器节点状态,服务器节点异常或工作出现故障,keepalived将故障节点从集群中删除,故障节点恢复后再重新将该节点加入集群
##################################################################################################	

*Haproxy
##################################################################################################

*Redis
##################################################################################################

*Mysql
	MySQL的复制原理及流程:
		主库开启binlog日志功能:logbin=mysql
			binlog线程会记录所有改变了数据库数据的语句,并将这些语句存放到binlog日志中
		从库设置主库信息,并启动slave功能后,会产生两个线程,一个是io线程,另一个是sql执行线程
			io线程负责拉取master上的binlog日志,并存放到自己的relay log中
			sql执行线程负责执行relay log日志中的语句
		
##################################################################################################

*Iptables
	rhel7以下版本使用iptables
	四表:
		filter:过滤表
		raw:状态跟踪表
		net:地址转换表
		mangle:包标记表
	五链
		INPUT:进入
		OUTPUT:出来
		PREROUTING:路由前
		POSTROUTING:路由后
		FORWARD:转发
	iptables包名:iptables-services
	操作用法:
		规则永久配置路径:
			/etc/sysconfig/iptables-conf
		修改链默认规则
			iptables -t filter -P INPUT DROP
			iptables -t raw -D
			iptables 
		封禁IP地址/网段
			#针对入站
			iptables -A INPUT-s 192.168.1.100 -j DROP
			iptables -A INPUT -s 192.168.1.0/24 -j ACCEPT
			#针对转发
			iptables -A FORWARD -s 192.168.1.100 -j DROP
			iptables -A FORWARD -s 192.168.1.0/24 -j ACCEPT
##################################################################################################
		
*Zabbix
	概念:
		zabbix是实现监控的工具
	为什么要监控:
		监控的目的就是为了预防会出现的故障
		1.对系统不间断的实时监控
		2.实时反馈系统当前状态
		3.保证服务可靠性安全性
		4.保证业务持续稳定运行
	能监控什么:
		1.硬件,如:路由器,防火墙,交换机
		2.系统状态,如:cpu负载,内存使用量,硬盘剩余空间,进程,网络连通性
		3.服务,如web服务,数据库服务
	zabbix如何实施监控:
		部署agentd到被监控的主机上,负责定期收集各项数据,并发送到zabbix服务端,zabbix服务端将数据存储到数据库中,zabbix web前端再根据数据进行图表展示;agentd分为两种工作模式:
						主动:agentd想server请求监控项,收集完数据之后主动将数据返回服务端
						被动:server向agentd请求数据,agentd返回相应数据
						如何选择工作模式:
							当被监控的主机300+,服务器承受的压力太大时,采用主动模式
	zabbix实现微信报警:
		需要微信公众号
		配置微信公众号私有接口
		zabbix添加报警类型,媒介,动作
	zabbix自定义监控项:
		在客户端设置zabbix_agentd.conf配置文件,Userparameter.现获取需要监控的数据,再书写agentd配置文件,设置Userparameter变量.zabbix添加监控项,设置键值为Userparameter
	多台客户端如何批量安装:
		使用ansible批量安装
			配置ssh免密登录
			添加需要安装客户端的主机进ansible hosts文件
			编写playbook脚本批量执行安装
	安装zabbix:
		基于LNMP环境
	自定义监控项:
		被监控的机器安装zabbix_agentd服务
		修改配置文件允许自定义监控项,加载配置文件目录
		在配置文件内书写监控key,监控的key可以使用脚本取值
		创建模板,设置监控项,应用集关联监控主机等
	zabbix报警:
		短信:需要跟运营商购买服务
		邮件:需要搭建邮件服务器
		触发器监控,达到条件后执行动作,动作是根据报警媒介信息发送邮件到指定邮件服务器
	自动发现:
		设置发现规则,满足规则会执行动作,自动添加满足规则的主机到zabbix监控主机中
	主被动监控:
		主动监控:agentd主动向server发起连接,agentd获取需要检测的监控项,agentd自行开始收集数据
		被动监控:server向agentd发起连接,发送监控key,agentd响应
##################################################################################################
	
*Docker
	基本概念:
		Docker本质上是宿主机上的一个进程.是一个能把开发应用程序自动部署到容器的开源引擎,基于Linux容器(LXC)等技术.Docker进行进一步封装,让用户不需要去关心容器的管理,使得操作更加便捷.
		通过namespace实现资源隔离(隔离主机名,隔离进程,隔离网络,隔离文件系统,隔离用户,隔离进程信号),cgroups实现资源管理,通过写时复制(cow)实现高效的文件操作
	特点:
		更快速的交付和部署
		更高效的虚拟化
		更轻松的迁移和扩展
		更简单的管理
	与虚拟机对比:
				Docker						虚拟机
		操作系统	与宿主机共享os(本质上是宿主机上的一个进程)		宿主机上运行虚拟os
		存储大小	镜像小(使用宿主机的资源)				镜像文件大(虚拟了一个完整的系统)
		运行性能	几乎无额外性能损失(本质上是宿主机上的一个进程)	CPU,内存性能损耗(虚拟的硬件,性能不好)
		移植性		轻便,灵活,适应于Linux				笨重,与虚拟化技术耦合度高
		硬件亲和性	面向软件开发者(本质上是一个进程,不涉及到硬件)	面向硬件运维者(先虚拟硬件,在虚拟硬件上运行)
		部署速度	快速,秒级(启动进程)					较慢(启动系统)
	Docker中的三个概念:
		镜像:后端存储,只读的模板.镜像制作可以基于别人的镜像之上,添加新的层次,以满足各种环境的使用
		容器:基于镜像快速创建的运行实例.每个容器之间相互隔离,因为镜像只读,容器在创建时会在镜像最上层添加一层可写层
		仓库:存放镜像的仓库.分为公共仓库(Docker hub)和私有仓库(私人搭建)

	Docker应用场景:
		web应用的自动化打包和发布
		自动化测试和持续集成,发布
		在服务型环境中部署和调整数据库或其他的后台应用

	部署Docker:
		环境:linux内核版本3.10以上
		包名:docker
		
		镜像操作:
		容器操作:
		
		

*Openstack

Ceph

DNS域名

网络项目




























